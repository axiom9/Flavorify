{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 15:59:32.405076: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-27 15:59:39.493313: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'fasttext_prep' from '/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/fasttext_prep.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import importlib\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "base_dir = '/Users/anasputhawala/Desktop/Winterproj/'\n",
    "sys.path.insert(0, base_dir)\n",
    "\n",
    "from src.utils import pre_processing\n",
    "from src.models.tfidf import config_tfidf\n",
    "import fasttext_prep\n",
    "importlib.reload(pre_processing)\n",
    "importlib.reload(config_tfidf)\n",
    "importlib.reload(fasttext_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test .txt files have successfully been saved at /Users/anasputhawala/Desktop/Winterproj/src/models/fasttext\n"
     ]
    }
   ],
   "source": [
    "fasttext_prep.load_prep_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 1M words\n",
      "Number of words:  88486\n",
      "Number of labels: 16\n",
      "Progress: 100.0% words/sec/thread:  910919 lr:  0.000000 avg.loss:  2.199809 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "train_path = '/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/train.txt'\n",
    "test_path = '/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/test.txt'\n",
    "model_ft = fasttext.train_supervised(input=train_path, wordNgrams=3, epoch=5, lr=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54420, 0.2984196986402058, 0.2984196986402058)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.test(test_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a different approach (gensim library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'fasttext_prep' from '/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/fasttext_prep.py'>"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import ft_model\n",
    "importlib.reload(ft_model)\n",
    "importlib.reload(fasttext_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).\n\nThe actual error from `call` is: Exception encountered when calling layer 'fast_text_embedding_82' (type FastTextEmbedding).\n\nin user code:\n\n    File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 26, in call  *\n        sent_tokenized = simple_preprocess(input)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 310, in simple_preprocess  *\n        tokens = [\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 262, in tokenize  *\n        text = to_unicode(text, encoding, errors=errors)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 365, in any2unicode  *\n        return str(text, encoding, errors=errors)\n\n    TypeError: decoding to str: need a bytes-like object, Tensor found\n\n\nCall arguments received by layer 'fast_text_embedding_82' (type FastTextEmbedding):\n  • input=tf.Tensor(shape=(204073,), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py:513\u001b[0m, in \u001b[0;36mModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    514\u001b[0m \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mInvalidArgumentError, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/Winterproj/src/models/fasttext/ft_model.py:96\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfasttext_embeddings(\u001b[39minput\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGot here\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflatten(x)\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filetq9re6sk.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     10\u001b[0m out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39mzeros, (), \u001b[39mdict\u001b[39m(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m60\u001b[39m)), fscope)\n\u001b[0;32m---> 11\u001b[0m sent_tokenized \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(simple_preprocess), (ag__\u001b[39m.\u001b[39mld(\u001b[39minput\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file5vqwqzck.py:32\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__simple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m     31\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 32\u001b[0m tokens \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39mld(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tokenize), (ag__\u001b[39m.\u001b[39mld(doc),), \u001b[39mdict\u001b[39m(lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, deacc\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(deacc), errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m), fscope) \u001b[39mif\u001b[39;00m ag__\u001b[39m.\u001b[39mand_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mand_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(min_len) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mlen\u001b[39m), (ag__\u001b[39m.\u001b[39mld(token),), \u001b[39mNone\u001b[39;00m, fscope), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mlen\u001b[39m), (ag__\u001b[39m.\u001b[39mld(token),), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(max_len)), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(token)\u001b[39m.\u001b[39mstartswith, (\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39mNone\u001b[39;00m, fscope)))]\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filezfaxoc93.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__tokenize\u001b[0;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[1;32m     44\u001b[0m lowercase \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mor_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(lowercase), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mor_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(to_lower), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(lower)))\n\u001b[0;32m---> 45\u001b[0m text \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(to_unicode), (ag__\u001b[39m.\u001b[39mld(text), ag__\u001b[39m.\u001b[39mld(encoding)), \u001b[39mdict\u001b[39m(errors\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(errors)), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py:53\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__any2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39misinstance\u001b[39m), (ag__\u001b[39m.\u001b[39mld(text), ag__\u001b[39m.\u001b[39mld(\u001b[39mstr\u001b[39m)), \u001b[39mNone\u001b[39;00m, fscope), if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39mdo_return\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mretval_\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m fscope\u001b[39m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py:49\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__any2unicode.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mstr\u001b[39m), (ag__\u001b[39m.\u001b[39mld(text), ag__\u001b[39m.\u001b[39mld(encoding)), \u001b[39mdict\u001b[39m(errors\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(errors)), fscope)\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'fast_text_embedding_82' (type FastTextEmbedding).\n\nin user code:\n\n    File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 26, in call  *\n        sent_tokenized = simple_preprocess(input)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 310, in simple_preprocess  *\n        tokens = [\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 262, in tokenize  *\n        text = to_unicode(text, encoding, errors=errors)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 365, in any2unicode  *\n        return str(text, encoding, errors=errors)\n\n    TypeError: decoding to str: need a bytes-like object, Tensor found\n\n\nCall arguments received by layer 'fast_text_embedding_82' (type FastTextEmbedding):\n  • input=tf.Tensor(shape=(204073,), dtype=float32)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[373], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m ft_model\u001b[39m.\u001b[39mFastTextModel(model_dir)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mbuild(input_shape\u001b[39m=\u001b[39;49mX_train\u001b[39m.\u001b[39;49mshape)\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py:515\u001b[0m, in \u001b[0;36mModel.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall(x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    514\u001b[0m         \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mInvalidArgumentError, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 515\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    516\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mYou cannot build your model by calling `build` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    517\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mif your layers do not support float type inputs. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    518\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mInstead, in order to instantiate and build your \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    519\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mmodel, call your model on real tensor data (of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    520\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mthe correct dtype).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThe actual error from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    521\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`call` is: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    522\u001b[0m             )\n\u001b[1;32m    523\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mbuild(input_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: You cannot build your model by calling `build` if your layers do not support float type inputs. Instead, in order to instantiate and build your model, call your model on real tensor data (of the correct dtype).\n\nThe actual error from `call` is: Exception encountered when calling layer 'fast_text_embedding_82' (type FastTextEmbedding).\n\nin user code:\n\n    File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 26, in call  *\n        sent_tokenized = simple_preprocess(input)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 310, in simple_preprocess  *\n        tokens = [\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 262, in tokenize  *\n        text = to_unicode(text, encoding, errors=errors)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 365, in any2unicode  *\n        return str(text, encoding, errors=errors)\n\n    TypeError: decoding to str: need a bytes-like object, Tensor found\n\n\nCall arguments received by layer 'fast_text_embedding_82' (type FastTextEmbedding):\n  • input=tf.Tensor(shape=(204073,), dtype=float32)."
     ]
    }
   ],
   "source": [
    "model = ft_model.FastTextModel(model_dir)\n",
    "model.build(input_shape=X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = fasttext_prep.load_gensim()\n",
    "# (X_train, y_train), (X_val, y_val), (X_test, y_test) = fasttext_prep.prep_gensim(df, tokenize=False, train_ratio=0.75, val_ratio=0.15, test_ratio=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using lambda layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filelbs1mcnw.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).fasttext_embeddings, (ag__.ld(input),), None, fscope)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filetq9re6sk.py\", line 11, in tf__call\n        sent_tokenized = ag__.converted_call(ag__.ld(simple_preprocess), (ag__.ld(input),), None, fscope)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file5vqwqzck.py\", line 32, in tf__simple_preprocess\n        tokens = [ag__.ld(token) for token in ag__.converted_call(ag__.ld(tokenize), (ag__.ld(doc),), dict(lower=True, deacc=ag__.ld(deacc), errors='ignore'), fscope) if ag__.and_(lambda : ag__.and_(lambda : ag__.ld(min_len) <= ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope), lambda : ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope) <= ag__.ld(max_len)), lambda : ag__.not_(ag__.converted_call(ag__.ld(token).startswith, ('_',), None, fscope)))]\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filezfaxoc93.py\", line 45, in tf__tokenize\n        text = ag__.converted_call(ag__.ld(to_unicode), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 53, in tf__any2unicode\n        ag__.if_stmt(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(text), ag__.ld(str)), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 49, in else_body\n        retval_ = ag__.converted_call(ag__.ld(str), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n\n    TypeError: Exception encountered when calling layer 'fast_text_model_19' (type FastTextModel).\n    \n    in user code:\n    \n        File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 96, in call  *\n            x = self.fasttext_embeddings(input)\n        File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filetq9re6sk.py\", line 11, in tf__call\n            sent_tokenized = ag__.converted_call(ag__.ld(simple_preprocess), (ag__.ld(input),), None, fscope)\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file5vqwqzck.py\", line 32, in tf__simple_preprocess\n            tokens = [ag__.ld(token) for token in ag__.converted_call(ag__.ld(tokenize), (ag__.ld(doc),), dict(lower=True, deacc=ag__.ld(deacc), errors='ignore'), fscope) if ag__.and_(lambda : ag__.and_(lambda : ag__.ld(min_len) <= ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope), lambda : ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope) <= ag__.ld(max_len)), lambda : ag__.not_(ag__.converted_call(ag__.ld(token).startswith, ('_',), None, fscope)))]\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filezfaxoc93.py\", line 45, in tf__tokenize\n            text = ag__.converted_call(ag__.ld(to_unicode), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 53, in tf__any2unicode\n            ag__.if_stmt(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(text), ag__.ld(str)), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 49, in else_body\n            retval_ = ag__.converted_call(ag__.ld(str), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n    \n        TypeError: Exception encountered when calling layer 'fast_text_embedding_81' (type FastTextEmbedding).\n        \n        in user code:\n        \n            File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 26, in call  *\n                sent_tokenized = simple_preprocess(input)\n            File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 310, in simple_preprocess  *\n                tokens = [\n            File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 262, in tokenize  *\n                text = to_unicode(text, encoding, errors=errors)\n            File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 365, in any2unicode  *\n                return str(text, encoding, errors=errors)\n        \n            TypeError: decoding to str: need a bytes-like object, Tensor found\n        \n        \n        Call arguments received by layer 'fast_text_embedding_81' (type FastTextEmbedding):\n          • input=tf.Tensor(shape=(None,), dtype=string)\n    \n    \n    Call arguments received by layer 'fast_text_model_19' (type FastTextModel):\n      • input=tf.Tensor(shape=(None,), dtype=string)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[372], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m LR\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39mLR), \n\u001b[1;32m      4\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mCategoricalCrossentropy(), \n\u001b[1;32m      5\u001b[0m               metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mCategoricalAccuracy()])\n\u001b[0;32m----> 7\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train,\n\u001b[1;32m      8\u001b[0m                     y_train,\n\u001b[1;32m      9\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m(X_val, y_val),\n\u001b[1;32m     11\u001b[0m                     validation_batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filerg_dksj0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filelbs1mcnw.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfasttext_embeddings, (ag__\u001b[39m.\u001b[39mld(\u001b[39minput\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m ag__\u001b[39m.\u001b[39mld(\u001b[39mprint\u001b[39m)(\u001b[39m'\u001b[39m\u001b[39mGot here\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m x \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mflatten, (ag__\u001b[39m.\u001b[39mld(x),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filetq9re6sk.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m out \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(np)\u001b[39m.\u001b[39mzeros, (), \u001b[39mdict\u001b[39m(shape\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m60\u001b[39m)), fscope)\n\u001b[0;32m---> 11\u001b[0m sent_tokenized \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(simple_preprocess), (ag__\u001b[39m.\u001b[39mld(\u001b[39minput\u001b[39m),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n\u001b[1;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file5vqwqzck.py:32\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__simple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m     30\u001b[0m do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 32\u001b[0m tokens \u001b[39m=\u001b[39m [ag__\u001b[39m.\u001b[39mld(token) \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tokenize), (ag__\u001b[39m.\u001b[39mld(doc),), \u001b[39mdict\u001b[39m(lower\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, deacc\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(deacc), errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m), fscope) \u001b[39mif\u001b[39;00m ag__\u001b[39m.\u001b[39mand_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mand_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(min_len) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mlen\u001b[39m), (ag__\u001b[39m.\u001b[39mld(token),), \u001b[39mNone\u001b[39;00m, fscope), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mlen\u001b[39m), (ag__\u001b[39m.\u001b[39mld(token),), \u001b[39mNone\u001b[39;00m, fscope) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(max_len)), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(token)\u001b[39m.\u001b[39mstartswith, (\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39mNone\u001b[39;00m, fscope)))]\n\u001b[1;32m     33\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filezfaxoc93.py:45\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__tokenize\u001b[0;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[1;32m     43\u001b[0m retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     44\u001b[0m lowercase \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mor_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(lowercase), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mor_(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(to_lower), \u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mld(lower)))\n\u001b[0;32m---> 45\u001b[0m text \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(to_unicode), (ag__\u001b[39m.\u001b[39mld(text), ag__\u001b[39m.\u001b[39mld(encoding)), \u001b[39mdict\u001b[39m(errors\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(errors)), fscope)\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state\u001b[39m():\n\u001b[1;32m     48\u001b[0m     \u001b[39mreturn\u001b[39;00m (text,)\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py:53\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__any2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m     51\u001b[0m         do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     52\u001b[0m         \u001b[39mraise\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39misinstance\u001b[39m), (ag__\u001b[39m.\u001b[39mld(text), ag__\u001b[39m.\u001b[39mld(\u001b[39mstr\u001b[39m)), \u001b[39mNone\u001b[39;00m, fscope), if_body, else_body, get_state, set_state, (\u001b[39m'\u001b[39m\u001b[39mdo_return\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mretval_\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m fscope\u001b[39m.\u001b[39mret(retval_, do_return)\n",
      "File \u001b[0;32m/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py:49\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__any2unicode.<locals>.else_body\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mstr\u001b[39m), (ag__\u001b[39m.\u001b[39mld(text), ag__\u001b[39m.\u001b[39mld(encoding)), \u001b[39mdict\u001b[39m(errors\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(errors)), fscope)\n\u001b[1;32m     50\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filelbs1mcnw.py\", line 10, in tf__call\n        x = ag__.converted_call(ag__.ld(self).fasttext_embeddings, (ag__.ld(input),), None, fscope)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filetq9re6sk.py\", line 11, in tf__call\n        sent_tokenized = ag__.converted_call(ag__.ld(simple_preprocess), (ag__.ld(input),), None, fscope)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file5vqwqzck.py\", line 32, in tf__simple_preprocess\n        tokens = [ag__.ld(token) for token in ag__.converted_call(ag__.ld(tokenize), (ag__.ld(doc),), dict(lower=True, deacc=ag__.ld(deacc), errors='ignore'), fscope) if ag__.and_(lambda : ag__.and_(lambda : ag__.ld(min_len) <= ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope), lambda : ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope) <= ag__.ld(max_len)), lambda : ag__.not_(ag__.converted_call(ag__.ld(token).startswith, ('_',), None, fscope)))]\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filezfaxoc93.py\", line 45, in tf__tokenize\n        text = ag__.converted_call(ag__.ld(to_unicode), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 53, in tf__any2unicode\n        ag__.if_stmt(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(text), ag__.ld(str)), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n    File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 49, in else_body\n        retval_ = ag__.converted_call(ag__.ld(str), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n\n    TypeError: Exception encountered when calling layer 'fast_text_model_19' (type FastTextModel).\n    \n    in user code:\n    \n        File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 96, in call  *\n            x = self.fasttext_embeddings(input)\n        File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filetq9re6sk.py\", line 11, in tf__call\n            sent_tokenized = ag__.converted_call(ag__.ld(simple_preprocess), (ag__.ld(input),), None, fscope)\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file5vqwqzck.py\", line 32, in tf__simple_preprocess\n            tokens = [ag__.ld(token) for token in ag__.converted_call(ag__.ld(tokenize), (ag__.ld(doc),), dict(lower=True, deacc=ag__.ld(deacc), errors='ignore'), fscope) if ag__.and_(lambda : ag__.and_(lambda : ag__.ld(min_len) <= ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope), lambda : ag__.converted_call(ag__.ld(len), (ag__.ld(token),), None, fscope) <= ag__.ld(max_len)), lambda : ag__.not_(ag__.converted_call(ag__.ld(token).startswith, ('_',), None, fscope)))]\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_filezfaxoc93.py\", line 45, in tf__tokenize\n            text = ag__.converted_call(ag__.ld(to_unicode), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 53, in tf__any2unicode\n            ag__.if_stmt(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(text), ag__.ld(str)), None, fscope), if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n        File \"/var/folders/07/1yqf9lq93hb3l2f96cqmmv9c0000gn/T/__autograph_generated_file76mj0j91.py\", line 49, in else_body\n            retval_ = ag__.converted_call(ag__.ld(str), (ag__.ld(text), ag__.ld(encoding)), dict(errors=ag__.ld(errors)), fscope)\n    \n        TypeError: Exception encountered when calling layer 'fast_text_embedding_81' (type FastTextEmbedding).\n        \n        in user code:\n        \n            File \"/Users/anasputhawala/Desktop/Winterproj/src/models/fasttext/ft_model.py\", line 26, in call  *\n                sent_tokenized = simple_preprocess(input)\n            File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 310, in simple_preprocess  *\n                tokens = [\n            File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 262, in tokenize  *\n                text = to_unicode(text, encoding, errors=errors)\n            File \"/Users/anasputhawala/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py\", line 365, in any2unicode  *\n                return str(text, encoding, errors=errors)\n        \n            TypeError: decoding to str: need a bytes-like object, Tensor found\n        \n        \n        Call arguments received by layer 'fast_text_embedding_81' (type FastTextEmbedding):\n          • input=tf.Tensor(shape=(None,), dtype=string)\n    \n    \n    Call arguments received by layer 'fast_text_model_19' (type FastTextModel):\n      • input=tf.Tensor(shape=(None,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "LR=0.001\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LR), \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(), \n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    batch_size=128,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    validation_batch_size=128,\n",
    "                    epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'fast_text_embedding_46' (type FastTextEmbedding).\n\ndecoding to str: need a bytes-like object, list found\n\nCall arguments received by layer 'fast_text_embedding_46' (type FastTextEmbedding):\n  • input=[\"'Hey my name is Anas'\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[319], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model([\u001b[39m\"\u001b[39;49m\u001b[39mHey my name is Anas\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/Winterproj/src/models/fasttext/ft_model.py:68\u001b[0m, in \u001b[0;36mFastTextModel.call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfasttext_embeddings(\u001b[39minput\u001b[39;49m,training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     69\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mGot here\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense1(x, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Winterproj/src/models/fasttext/ft_model.py:30\u001b[0m, in \u001b[0;36mFastTextEmbedding.call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     28\u001b[0m def call(self, input):\n\u001b[1;32m     29\u001b[0m     out = np.zeros(shape=(1,60))\n\u001b[0;32m---> 30\u001b[0m     # sent_tokenized = simple_preprocess(input)\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m     # we'll use mean pooling\n\u001b[1;32m     33\u001b[0m     for word in input:\n\u001b[1;32m     34\u001b[0m         out[:,:] += self.trained_ft_model.wv[word]\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py:311\u001b[0m, in \u001b[0;36msimple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msimple_preprocess\u001b[39m(doc, deacc\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, min_len\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, max_len\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m):\n\u001b[1;32m    289\u001b[0m     \u001b[39m\"\"\"Convert a document into a list of lowercase tokens, ignoring tokens that are too short or too long.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \n\u001b[1;32m    291\u001b[0m \u001b[39m    Uses :func:`~gensim.utils.tokenize` internally.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \n\u001b[1;32m    309\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m     tokens \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 311\u001b[0m         token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m tokenize(doc, lower\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, deacc\u001b[39m=\u001b[39;49mdeacc, errors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mignore\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    312\u001b[0m         \u001b[39mif\u001b[39;00m min_len \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(token) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m max_len \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m token\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    313\u001b[0m     ]\n\u001b[1;32m    314\u001b[0m     \u001b[39mreturn\u001b[39;00m tokens\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py:262\u001b[0m, in \u001b[0;36mtokenize\u001b[0;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m\"\"\"Iteratively yield tokens as unicode strings, optionally removing accent marks and lowercasing it.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \n\u001b[1;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m lowercase \u001b[39m=\u001b[39m lowercase \u001b[39mor\u001b[39;00m to_lower \u001b[39mor\u001b[39;00m lower\n\u001b[0;32m--> 262\u001b[0m text \u001b[39m=\u001b[39m to_unicode(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m lowercase:\n\u001b[1;32m    264\u001b[0m     text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mlower()\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/gensim/utils.py:365\u001b[0m, in \u001b[0;36many2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    364\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n\u001b[0;32m--> 365\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39;49m(text, encoding, errors\u001b[39m=\u001b[39;49merrors)\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'fast_text_embedding_46' (type FastTextEmbedding).\n\ndecoding to str: need a bytes-like object, list found\n\nCall arguments received by layer 'fast_text_embedding_46' (type FastTextEmbedding):\n  • input=[\"'Hey my name is Anas'\"]"
     ]
    }
   ],
   "source": [
    "model([\"Hey my name is Anas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = FastText.load(model_dir)\n",
    "def p(text):\n",
    "    sent_tokenized = text.lower().split(' ')\n",
    "    out = np.zeros(shape=(60,))\n",
    "    # sent_tokenized = simple_preprocess(input)\n",
    "\n",
    "    # we'll use mean pooling\n",
    "    for word in sent_tokenized:\n",
    "        out[:] += m.wv[word]\n",
    "    \n",
    "    return tf.convert_to_tensor(out / len(sent_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=20000,\n",
    "            standardize='lower_and_strip_punctuation',\n",
    "            split='whitespace',\n",
    "            ngrams=None,\n",
    "            output_mode='int',\n",
    "            output_sequence_length = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec.adapt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ft_model.FastTextModel at 0x16b1d1d00>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \u001b[0mtest_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           TextVectorization\n",
      "\u001b[0;31mString form:\u001b[0m    <keras.layers.preprocessing.text_vectorization.TextVectorization object at 0x169ec3fa0>\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/layers/preprocessing/text_vectorization.py\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"keras.layers.TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"keras.layers.experimental.preprocessing.TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_preprocessing_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreprocessingLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"A preprocessing layer which maps text features to integer sequences.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This layer has basic options for managing text in a Keras model. It\u001b[0m\n",
      "\u001b[0;34m    transforms a batch of strings (one example = one string) into either a list\u001b[0m\n",
      "\u001b[0;34m    of token indices (one example = 1D tensor of integer token indices) or a\u001b[0m\n",
      "\u001b[0;34m    dense representation (one example = 1D tensor of float values representing\u001b[0m\n",
      "\u001b[0;34m    data about the example's tokens). This layer is meant to handle natural\u001b[0m\n",
      "\u001b[0;34m    language inputs. To handle simple string inputs (categorical strings or\u001b[0m\n",
      "\u001b[0;34m    pre-tokenized strings) see `tf.keras.layers.StringLookup`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The vocabulary for the layer must be either supplied on construction or\u001b[0m\n",
      "\u001b[0;34m    learned via `adapt()`. When this layer is adapted, it will analyze the\u001b[0m\n",
      "\u001b[0;34m    dataset, determine the frequency of individual string values, and create a\u001b[0m\n",
      "\u001b[0;34m    vocabulary from them. This vocabulary can have unlimited size or be capped,\u001b[0m\n",
      "\u001b[0;34m    depending on the configuration options for this layer; if there are more\u001b[0m\n",
      "\u001b[0;34m    unique values in the input than the maximum vocabulary size, the most\u001b[0m\n",
      "\u001b[0;34m    frequent terms will be used to create the vocabulary.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The processing of each example contains the following steps:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    1. Standardize each example (usually lowercasing + punctuation stripping)\u001b[0m\n",
      "\u001b[0;34m    2. Split each example into substrings (usually words)\u001b[0m\n",
      "\u001b[0;34m    3. Recombine substrings into tokens (usually ngrams)\u001b[0m\n",
      "\u001b[0;34m    4. Index tokens (associate a unique int value with each token)\u001b[0m\n",
      "\u001b[0;34m    5. Transform each example using this index, either into a vector of ints or\u001b[0m\n",
      "\u001b[0;34m       a dense float vector.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Some notes on passing callables to customize splitting and normalization for\u001b[0m\n",
      "\u001b[0;34m    this layer:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    1. Any callable can be passed to this Layer, but if you want to serialize\u001b[0m\n",
      "\u001b[0;34m       this object you should only pass functions that are registered Keras\u001b[0m\n",
      "\u001b[0;34m       serializables (see `tf.keras.utils.register_keras_serializable` for more\u001b[0m\n",
      "\u001b[0;34m       details).\u001b[0m\n",
      "\u001b[0;34m    2. When using a custom callable for `standardize`, the data received\u001b[0m\n",
      "\u001b[0;34m       by the callable will be exactly as passed to this layer. The callable\u001b[0m\n",
      "\u001b[0;34m       should return a tensor of the same shape as the input.\u001b[0m\n",
      "\u001b[0;34m    3. When using a custom callable for `split`, the data received by the\u001b[0m\n",
      "\u001b[0;34m       callable will have the 1st dimension squeezed out - instead of\u001b[0m\n",
      "\u001b[0;34m       `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\u001b[0m\n",
      "\u001b[0;34m       see `[\"string to split\", \"another string to split\"]`. The callable should\u001b[0m\n",
      "\u001b[0;34m       return a Tensor with the first dimension containing the split tokens -\u001b[0m\n",
      "\u001b[0;34m       in this example, we should see something like `[[\"string\", \"to\",\u001b[0m\n",
      "\u001b[0;34m       \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\u001b[0m\n",
      "\u001b[0;34m       site natively compatible with `tf.strings.split()`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For an overview and full list of preprocessing layers, see the preprocessing\u001b[0m\n",
      "\u001b[0;34m    [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Args:\u001b[0m\n",
      "\u001b[0;34m      max_tokens: Maximum size of the vocabulary for this layer. This should\u001b[0m\n",
      "\u001b[0;34m        only be specified when adapting a vocabulary or when setting\u001b[0m\n",
      "\u001b[0;34m        `pad_to_max_tokens=True`. Note that this vocabulary\u001b[0m\n",
      "\u001b[0;34m        contains 1 OOV token, so the effective number of tokens is\u001b[0m\n",
      "\u001b[0;34m        `(max_tokens - 1 - (1 if output_mode == \"int\" else 0))`.\u001b[0m\n",
      "\u001b[0;34m      standardize: Optional specification for standardization to apply to the\u001b[0m\n",
      "\u001b[0;34m        input text. Values can be:\u001b[0m\n",
      "\u001b[0;34m          - `None`: No standardization.\u001b[0m\n",
      "\u001b[0;34m          - `\"lower_and_strip_punctuation\"`: Text will be lowercased and all\u001b[0m\n",
      "\u001b[0;34m            punctuation removed.\u001b[0m\n",
      "\u001b[0;34m          - `\"lower\"`: Text will be lowercased.\u001b[0m\n",
      "\u001b[0;34m          - `\"strip_punctuation\"`: All punctuation will be removed.\u001b[0m\n",
      "\u001b[0;34m          - Callable: Inputs will passed to the callable function, which should\u001b[0m\n",
      "\u001b[0;34m            standardized and returned.\u001b[0m\n",
      "\u001b[0;34m      split: Optional specification for splitting the input text. Values can be:\u001b[0m\n",
      "\u001b[0;34m          - `None`: No splitting.\u001b[0m\n",
      "\u001b[0;34m          - `\"whitespace\"`: Split on whitespace.\u001b[0m\n",
      "\u001b[0;34m          - `\"character\"`: Split on each unicode character.\u001b[0m\n",
      "\u001b[0;34m          - Callable: Standardized inputs will passed to the callable function,\u001b[0m\n",
      "\u001b[0;34m            which should split and returned.\u001b[0m\n",
      "\u001b[0;34m      ngrams: Optional specification for ngrams to create from the\u001b[0m\n",
      "\u001b[0;34m        possibly-split input text. Values can be None, an integer or tuple of\u001b[0m\n",
      "\u001b[0;34m        integers; passing an integer will create ngrams up to that integer, and\u001b[0m\n",
      "\u001b[0;34m        passing a tuple of integers will create ngrams for the specified values\u001b[0m\n",
      "\u001b[0;34m        in the tuple. Passing None means that no ngrams will be created.\u001b[0m\n",
      "\u001b[0;34m      output_mode: Optional specification for the output of the layer. Values\u001b[0m\n",
      "\u001b[0;34m        can be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the\u001b[0m\n",
      "\u001b[0;34m        layer as follows:\u001b[0m\n",
      "\u001b[0;34m          - `\"int\"`: Outputs integer indices, one integer index per split string\u001b[0m\n",
      "\u001b[0;34m            token. When `output_mode == \"int\"`, 0 is reserved for masked\u001b[0m\n",
      "\u001b[0;34m            locations; this reduces the vocab size to\u001b[0m\n",
      "\u001b[0;34m            `max_tokens - 2` instead of `max_tokens - 1`.\u001b[0m\n",
      "\u001b[0;34m          - `\"multi_hot\"`: Outputs a single int array per batch, of either\u001b[0m\n",
      "\u001b[0;34m            vocab_size or max_tokens size, containing 1s in all elements where\u001b[0m\n",
      "\u001b[0;34m            the token mapped to that index exists at least once in the batch\u001b[0m\n",
      "\u001b[0;34m            item.\u001b[0m\n",
      "\u001b[0;34m          - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\u001b[0m\n",
      "\u001b[0;34m            the number of times the token at that index appeared in the\u001b[0m\n",
      "\u001b[0;34m            batch item.\u001b[0m\n",
      "\u001b[0;34m          - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied\u001b[0m\n",
      "\u001b[0;34m            to find the value in each token slot.\u001b[0m\n",
      "\u001b[0;34m        For `\"int\"` output, any shape of input and output is supported. For all\u001b[0m\n",
      "\u001b[0;34m        other output modes, currently only rank 1 inputs (and rank 2 outputs\u001b[0m\n",
      "\u001b[0;34m        after splitting) are supported.\u001b[0m\n",
      "\u001b[0;34m      output_sequence_length: Only valid in INT mode. If set, the output will\u001b[0m\n",
      "\u001b[0;34m        have its time dimension padded or truncated to exactly\u001b[0m\n",
      "\u001b[0;34m        `output_sequence_length` values, resulting in a tensor of shape\u001b[0m\n",
      "\u001b[0;34m        `(batch_size, output_sequence_length)` regardless of how many tokens\u001b[0m\n",
      "\u001b[0;34m        resulted from the splitting step. Defaults to None.\u001b[0m\n",
      "\u001b[0;34m      pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\u001b[0m\n",
      "\u001b[0;34m        modes. If True, the output will have its feature axis padded to\u001b[0m\n",
      "\u001b[0;34m        `max_tokens` even if the number of unique tokens in the vocabulary is\u001b[0m\n",
      "\u001b[0;34m        less than max_tokens, resulting in a tensor of shape `(batch_size,\u001b[0m\n",
      "\u001b[0;34m        max_tokens)` regardless of vocabulary size. Defaults to False.\u001b[0m\n",
      "\u001b[0;34m      vocabulary: Optional. Either an array of strings or a string path to a\u001b[0m\n",
      "\u001b[0;34m        text file. If passing an array, can pass a tuple, list, 1D numpy array,\u001b[0m\n",
      "\u001b[0;34m        or 1D tensor containing the string vocbulary terms. If passing a file\u001b[0m\n",
      "\u001b[0;34m        path, the file should contain one line per term in the vocabulary. If\u001b[0m\n",
      "\u001b[0;34m        this argument is set, there is no need to `adapt()` the layer.\u001b[0m\n",
      "\u001b[0;34m      idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list,\u001b[0m\n",
      "\u001b[0;34m        1D numpy array, or 1D tensor or the same length as the vocabulary,\u001b[0m\n",
      "\u001b[0;34m        containing the floating point inverse document frequency weights, which\u001b[0m\n",
      "\u001b[0;34m        will be multiplied by per sample term counts for the final `tf_idf`\u001b[0m\n",
      "\u001b[0;34m        weight. If the `vocabulary` argument is set, and `output_mode` is\u001b[0m\n",
      "\u001b[0;34m        `\"tf_idf\"`, this argument must be supplied.\u001b[0m\n",
      "\u001b[0;34m      ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns\u001b[0m\n",
      "\u001b[0;34m        a `RaggedTensor` instead of a dense `Tensor`, where each sequence may\u001b[0m\n",
      "\u001b[0;34m        have a different length after string splitting. Defaults to False.\u001b[0m\n",
      "\u001b[0;34m      sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\u001b[0m\n",
      "\u001b[0;34m        `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\u001b[0m\n",
      "\u001b[0;34m        dense `Tensor`. Defaults to False.\u001b[0m\n",
      "\u001b[0;34m      encoding: Optional. The text encoding to use to interpret the input\u001b[0m\n",
      "\u001b[0;34m        strings. Defaults to `\"utf-8\"`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This example instantiates a `TextVectorization` layer that lowercases text,\u001b[0m\n",
      "\u001b[0;34m    splits on whitespace, strips punctuation, and outputs integer vocab indices.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\u001b[0m\n",
      "\u001b[0;34m    >>> max_features = 5000  # Maximum vocab size.\u001b[0m\n",
      "\u001b[0;34m    >>> max_len = 4  # Sequence length to pad the outputs to.\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Create the layer.\u001b[0m\n",
      "\u001b[0;34m    >>> vectorize_layer = tf.keras.layers.TextVectorization(\u001b[0m\n",
      "\u001b[0;34m    ...  max_tokens=max_features,\u001b[0m\n",
      "\u001b[0;34m    ...  output_mode='int',\u001b[0m\n",
      "\u001b[0;34m    ...  output_sequence_length=max_len)\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Now that the vocab layer has been created, call `adapt` on the\u001b[0m\n",
      "\u001b[0;34m    >>> # text-only dataset to create the vocabulary. You don't have to batch,\u001b[0m\n",
      "\u001b[0;34m    >>> # but for large datasets this means we're not keeping spare copies of\u001b[0m\n",
      "\u001b[0;34m    >>> # the dataset.\u001b[0m\n",
      "\u001b[0;34m    >>> vectorize_layer.adapt(text_dataset.batch(64))\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Create the model that uses the vectorize text layer\u001b[0m\n",
      "\u001b[0;34m    >>> model = tf.keras.models.Sequential()\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Start by creating an explicit input layer. It needs to have a shape of\u001b[0m\n",
      "\u001b[0;34m    >>> # (1,) (because we need to guarantee that there is exactly one string\u001b[0m\n",
      "\u001b[0;34m    >>> # input per batch), and the dtype needs to be 'string'.\u001b[0m\n",
      "\u001b[0;34m    >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # The first layer in our model is the vectorization layer. After this\u001b[0m\n",
      "\u001b[0;34m    >>> # layer, we have a tensor of shape (batch_size, max_len) containing\u001b[0m\n",
      "\u001b[0;34m    >>> # vocab indices.\u001b[0m\n",
      "\u001b[0;34m    >>> model.add(vectorize_layer)\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Now, the model can map strings to integers, and you can add an\u001b[0m\n",
      "\u001b[0;34m    >>> # embedding layer to map these integers to learned embeddings.\u001b[0m\n",
      "\u001b[0;34m    >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\u001b[0m\n",
      "\u001b[0;34m    >>> model.predict(input_data)\u001b[0m\n",
      "\u001b[0;34m    array([[2, 1, 4, 0],\u001b[0m\n",
      "\u001b[0;34m           [1, 3, 0, 0]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    This example instantiates a `TextVectorization` layer by passing a list\u001b[0m\n",
      "\u001b[0;34m    of vocabulary terms to the layer's `__init__()` method.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\u001b[0m\n",
      "\u001b[0;34m    >>> max_len = 4  # Sequence length to pad the outputs to.\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Create the layer, passing the vocab directly. You can also pass the\u001b[0m\n",
      "\u001b[0;34m    >>> # vocabulary arg a path to a file containing one vocabulary word per\u001b[0m\n",
      "\u001b[0;34m    >>> # line.\u001b[0m\n",
      "\u001b[0;34m    >>> vectorize_layer = tf.keras.layers.TextVectorization(\u001b[0m\n",
      "\u001b[0;34m    ...  max_tokens=max_features,\u001b[0m\n",
      "\u001b[0;34m    ...  output_mode='int',\u001b[0m\n",
      "\u001b[0;34m    ...  output_sequence_length=max_len,\u001b[0m\n",
      "\u001b[0;34m    ...  vocabulary=vocab_data)\u001b[0m\n",
      "\u001b[0;34m    >>>\u001b[0m\n",
      "\u001b[0;34m    >>> # Because we've passed the vocabulary directly, we don't need to adapt\u001b[0m\n",
      "\u001b[0;34m    >>> # the layer - the vocabulary is already set. The vocabulary contains the\u001b[0m\n",
      "\u001b[0;34m    >>> # padding token ('') and OOV token ('[UNK]') as well as the passed\u001b[0m\n",
      "\u001b[0;34m    >>> # tokens.\u001b[0m\n",
      "\u001b[0;34m    >>> vectorize_layer.get_vocabulary()\u001b[0m\n",
      "\u001b[0;34m    ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mstandardize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower_and_strip_punctuation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"whitespace\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mngrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mragged\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# This layer only applies to string processing, and so should only have\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# a dtype of 'string'.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"`TextVectorization` may only have a dtype of string. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Received dtype: {kwargs['dtype']}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 'standardize' must be one of\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# (None, LOWER_AND_STRIP_PUNCTUATION, LOWER, STRIP_PUNCTUATION,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# callable)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mstandardize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallowable_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mLOWER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mSTRIP_PUNCTUATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"standardize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallow_callables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 'split' must be one of (None, WHITESPACE, CHARACTER, callable)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallowable_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWHITESPACE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHARACTER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallow_callables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Support deprecated names for output_modes.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMULTI_HOT\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tf-idf\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTF_IDF\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 'output_mode' must be one of (None, INT, COUNT, MULTI_HOT, TF_IDF)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_string_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallowable_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCOUNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMULTI_HOT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTF_IDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlayer_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0marg_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_mode\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mallow_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 'ngrams' must be one of (None, int, tuple(int))\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"`ngrams` must be None, an integer, or a tuple of \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"integers. Received: ngrams={ngrams}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# 'output_sequence_length' must be one of (None, int) and is only\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# set if output_mode is INT.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"`output_sequence_length` must be either None or an \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"integer when `output_mode` is 'int'. Received: \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"output_sequence_length={output_sequence_length}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mINT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"`output_sequence_length` must not be set if `output_mode` is \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"not 'int'. \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Received output_sequence_length={output_sequence_length}.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mragged\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"`ragged` must not be true if `output_mode` is \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"`'int'`. Received: ragged={ragged} and \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"output_mode={output_mode}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mragged\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0moutput_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"`output_sequence_length` must not be set if ragged \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"is True. Received: ragged={ragged} and \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"output_sequence_length={output_sequence_length}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ragged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mragged\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_mode\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_sequence_length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# VocabularySavedModelSaver will clear the config vocabulary to restore\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# the lookup table ops directly. We persist this hidden option to\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# persist the fact that we have have a non-adaptable layer with a\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# manually set vocab.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_input_vocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"has_input_vocabulary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Drop deprecated config options.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vocabulary_size\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbase_preprocessing_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_kpl_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"TextVectorization\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_lookup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmask_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_mode\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mhas_input_vocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_input_vocabulary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m[\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moutput_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mINT\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# We override this method solely to generate a docstring.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Computes a vocabulary of string terms from tokens in a dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Calling `adapt()` on a `TextVectorization` layer is an alternative to\u001b[0m\n",
      "\u001b[0;34m        passing in a precomputed vocabulary on construction via the `vocabulary`\u001b[0m\n",
      "\u001b[0;34m        argument. A `TextVectorization` layer should always be either adapted\u001b[0m\n",
      "\u001b[0;34m        over a dataset or supplied with a vocabulary.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        During `adapt()`, the layer will build a vocabulary of all string tokens\u001b[0m\n",
      "\u001b[0;34m        seen in the dataset, sorted by occurrence count, with ties broken by\u001b[0m\n",
      "\u001b[0;34m        sort order of the tokens (high to low). At the end of `adapt()`, if\u001b[0m\n",
      "\u001b[0;34m        `max_tokens` is set, the vocabulary wil be truncated to `max_tokens`\u001b[0m\n",
      "\u001b[0;34m        size. For example, adapting a layer with `max_tokens=1000` will compute\u001b[0m\n",
      "\u001b[0;34m        the 1000 most frequent tokens occurring in the input dataset. If\u001b[0m\n",
      "\u001b[0;34m        `output_mode='tf-idf'`, `adapt()` will also learn the document\u001b[0m\n",
      "\u001b[0;34m        frequencies of each token in the input dataset.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        In order to make `TextVectorization` efficient in any distribution\u001b[0m\n",
      "\u001b[0;34m        context, the vocabulary is kept static with respect to any compiled\u001b[0m\n",
      "\u001b[0;34m        `tf.Graph`s that call the layer. As a consequence, if the layer is\u001b[0m\n",
      "\u001b[0;34m        adapted a second time, any models using the layer should be re-compiled.\u001b[0m\n",
      "\u001b[0;34m        For more information see\u001b[0m\n",
      "\u001b[0;34m        `tf.keras.layers.experimental.preprocessing.PreprocessingLayer.adapt`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        `adapt()` is meant only as a single machine utility to compute layer\u001b[0m\n",
      "\u001b[0;34m        state.  To analyze a dataset that cannot fit on a single machine, see\u001b[0m\n",
      "\u001b[0;34m        [Tensorflow Transform](\u001b[0m\n",
      "\u001b[0;34m        https://www.tensorflow.org/tfx/transform/get_started) for a\u001b[0m\n",
      "\u001b[0;34m        multi-machine, map-reduce solution.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Arguments:\u001b[0m\n",
      "\u001b[0;34m          data: The data to train on. It can be passed either as a\u001b[0m\n",
      "\u001b[0;34m              `tf.data.Dataset`, or as a numpy array.\u001b[0m\n",
      "\u001b[0;34m          batch_size: Integer or `None`.\u001b[0m\n",
      "\u001b[0;34m              Number of samples per state update.\u001b[0m\n",
      "\u001b[0;34m              If unspecified, `batch_size` will default to 32.\u001b[0m\n",
      "\u001b[0;34m              Do not specify the `batch_size` if your data is in the\u001b[0m\n",
      "\u001b[0;34m              form of datasets, generators, or `keras.utils.Sequence` instances\u001b[0m\n",
      "\u001b[0;34m              (since they generate batches).\u001b[0m\n",
      "\u001b[0;34m          steps: Integer or `None`.\u001b[0m\n",
      "\u001b[0;34m              Total number of steps (batches of samples)\u001b[0m\n",
      "\u001b[0;34m              When training with input tensors such as\u001b[0m\n",
      "\u001b[0;34m              TensorFlow data tensors, the default `None` is equal to\u001b[0m\n",
      "\u001b[0;34m              the number of samples in your dataset divided by\u001b[0m\n",
      "\u001b[0;34m              the batch size, or 1 if that cannot be determined. If x is a\u001b[0m\n",
      "\u001b[0;34m              `tf.data` dataset, and 'steps' is None, the epoch will run until\u001b[0m\n",
      "\u001b[0;34m              the input dataset is exhausted. When passing an infinitely\u001b[0m\n",
      "\u001b[0;34m              repeating dataset, you must specify the `steps` argument. This\u001b[0m\n",
      "\u001b[0;34m              argument is not supported with array inputs.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mfinalize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Returns the current vocabulary of the layer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m          include_special_tokens: If True, the returned vocabulary will include\u001b[0m\n",
      "\u001b[0;34m            the padding and OOV tokens, and a term's index in the vocabulary\u001b[0m\n",
      "\u001b[0;34m            will equal the term's index when calling the layer. If False, the\u001b[0m\n",
      "\u001b[0;34m            returned vocabulary will not include any padding or OOV tokens.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Gets the current size of the layer's vocabulary.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns:\u001b[0m\n",
      "\u001b[0;34m          The integer size of the vocabulary, including optional mask and\u001b[0m\n",
      "\u001b[0;34m          OOV indices.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_vocabulary\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0midf_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_idf_weights\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"max_tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"standardize\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"ngrams\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams_arg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"output_mode\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"output_sequence_length\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"pad_to_max_tokens\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_max_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"sparse\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"ragged\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ragged\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"vocabulary\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistify_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"idf_weights\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistify_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mbase_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mset_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Sets vocabulary (and optionally document frequency) data for this layer.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        This method sets the vocabulary and idf weights for this layer directly,\u001b[0m\n",
      "\u001b[0;34m        instead of analyzing a dataset through 'adapt'. It should be used\u001b[0m\n",
      "\u001b[0;34m        whenever the vocab (and optionally document frequency) information is\u001b[0m\n",
      "\u001b[0;34m        already known.  If vocabulary data is already present in the layer, this\u001b[0m\n",
      "\u001b[0;34m        method will replace it.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m          vocabulary: Either an array or a string path to a text file. If\u001b[0m\n",
      "\u001b[0;34m            passing an array, can pass a tuple, list, 1D numpy array, or 1D\u001b[0m\n",
      "\u001b[0;34m            tensor containing the vocbulary terms. If passing a file path, the\u001b[0m\n",
      "\u001b[0;34m            file should contain one line per term in the vocabulary.\u001b[0m\n",
      "\u001b[0;34m          idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse\u001b[0m\n",
      "\u001b[0;34m            document frequency weights with equal length to vocabulary. Must be\u001b[0m\n",
      "\u001b[0;34m            set if `output_mode` is `\"tf_idf\"`. Should not be set otherwise.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Raises:\u001b[0m\n",
      "\u001b[0;34m          ValueError: If there are too many inputs, the inputs do not match, or\u001b[0m\n",
      "\u001b[0;34m            input data is missing.\u001b[0m\n",
      "\u001b[0;34m          RuntimeError: If the vocabulary cannot be set when this function is\u001b[0m\n",
      "\u001b[0;34m            called. This happens when `\"multi_hot\"`, `\"count\"`, and \"tf_idf\"\u001b[0m\n",
      "\u001b[0;34m            modes, if `pad_to_max_tokens` is False and the layer itself has\u001b[0m\n",
      "\u001b[0;34m            already been called.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midf_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midf_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLOWER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mSTRIP_PUNCTUATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mLOWER_AND_STRIP_PUNCTUATION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregex_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_STRIP_REGEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# If we are splitting, we validate that the 1st axis is of dimension\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# 1 and so can be squeezed out. We do this here instead of after\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# splitting for performance reasons - it's more expensive to squeeze\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# a ragged tensor.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"When using `TextVectorization` to tokenize strings, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m\"the input rank must be 1 or the last shape dimension \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"must be 1. Received: inputs.shape={inputs.shape} \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"with rank={inputs.shape.rank}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mWHITESPACE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# This treats multiple whitespaces as one whitespace, and strips\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# leading and trailing whitespace.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mCHARACTER\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0municode_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"%s is not a supported splitting.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"TextVectorization supports the following options \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"for `split`: None, 'whitespace', or a Callable.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Note that 'inputs' here can be either ragged or dense depending on the\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# configuration choices for this Layer. The strings.ngrams op, however,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# does support both ragged and dense inputs.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ngrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# If we're not doing any output processing, return right away.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlookup_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# For any non-int output, we can return directly from the underlying\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# layer.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_mode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mINT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ragged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# If we have a ragged tensor, we can pad during the conversion to dense.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ragged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# If output sequence length is None, to_tensor will pad the last\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# dimension to the bounding shape of the ragged dimension.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# If we have a dense tensor, we need to pad/trim directly.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Maybe trim the output.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlookup_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Maybe pad the output. We need to be careful to use dynamic shape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# here as required_space_to_batch_paddings requires a fully known\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# shape.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpadded_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_sequence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequired_space_to_batch_paddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_shape\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookup_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlookup_data\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m_trackable_saved_model_saver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_serialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVocabularySavedModelSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCall docstring:\u001b[0m\n",
      "Wraps `call`, applying pre- and post-processing steps.\n",
      "\n",
      "Args:\n",
      "  *args: Positional arguments to be passed to `self.call`.\n",
      "  **kwargs: Keyword arguments to be passed to `self.call`.\n",
      "\n",
      "Returns:\n",
      "  Output tensor(s).\n",
      "\n",
      "Note:\n",
      "  - The following optional keyword arguments are reserved for specific\n",
      "    uses:\n",
      "    * `training`: Boolean scalar tensor of Python boolean indicating\n",
      "      whether the `call` is meant for training or inference.\n",
      "    * `mask`: Boolean input mask.\n",
      "  - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      "    layers do), its default value will be set to the mask generated\n",
      "    for `inputs` by the previous layer (if `input` did come from\n",
      "    a layer that generated a corresponding mask, i.e. if it came from\n",
      "    a Keras layer with masking support.\n",
      "  - If the layer is not built, the method will call `build`.\n",
      "\n",
      "Raises:\n",
      "  ValueError: if the layer's `call` method returns None (an invalid\n",
      "    value).\n",
      "  RuntimeError: if `super().__init__()` was not called in the\n",
      "    constructor.\n"
     ]
    }
   ],
   "source": [
    "test_vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"lambda_6\" (type Lambda).\n\n'Tensor' object has no attribute 'lower'\n\nCall arguments received by layer \"lambda_6\" (type Lambda):\n  • inputs=tf.Tensor(shape=(None, 204073), dtype=string)\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[294], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m inp \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# embedding = ft_embedding(inp)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m embedding \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLambda(\u001b[39mlambda\u001b[39;49;00m z: p(z))(inp)\n\u001b[1;32m      7\u001b[0m dense \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)(embedding)\n\u001b[1;32m      9\u001b[0m m2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39minp, outputs\u001b[39m=\u001b[39mdense)\n",
      "File \u001b[0;32m~/Desktop/Winterproj/emojify/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[294], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      4\u001b[0m inp \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstring\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39m# embedding = ft_embedding(inp)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m embedding \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLambda(\u001b[39mlambda\u001b[39;00m z: p(z))(inp)\n\u001b[1;32m      7\u001b[0m dense \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m)(embedding)\n\u001b[1;32m      9\u001b[0m m2 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mModel(inputs\u001b[39m=\u001b[39minp, outputs\u001b[39m=\u001b[39mdense)\n",
      "Cell \u001b[0;32mIn[293], line 3\u001b[0m, in \u001b[0;36mp\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mp\u001b[39m(text):\n\u001b[0;32m----> 3\u001b[0m     sent_tokenized \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39;49mlower()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39m60\u001b[39m,))\n\u001b[1;32m      5\u001b[0m     \u001b[39m# sent_tokenized = simple_preprocess(input)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     \u001b[39m# we'll use mean pooling\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling layer \"lambda_6\" (type Lambda).\n\n'Tensor' object has no attribute 'lower'\n\nCall arguments received by layer \"lambda_6\" (type Lambda):\n  • inputs=tf.Tensor(shape=(None, 204073), dtype=string)\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "# ft_embedding = ft_model.FastTextEmbedding(trained_ft_model_dir=model_dir)\n",
    "# ft_embedding.build(input_shape=[])\n",
    "\n",
    "inp = tf.keras.Input(shape=X_train.shape, dtype=\"string\")\n",
    "# embedding = ft_embedding(inp)\n",
    "embedding = tf.keras.layers.Lambda(lambda z: p(z))(inp)\n",
    "dense = tf.keras.layers.Dense(units=16, activation='softmax')(embedding)\n",
    "\n",
    "m2 = tf.keras.Model(inputs=inp, outputs=dense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: ['chick fil hicksville finally open'\n",
      " 'accidental twinning with my favorites'\n",
      " 'one of my favorite people in this world love you mrs andrews' ...\n",
      " 'of your fav artists takin on hoco' 'welcome to the studio' 'the boys']\n",
      "\n",
      "shape of training data: (204073,)\n",
      "\n",
      "\n",
      "Labels for data: [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "shape of labels for training: (204073, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training data: {X_train}\\n\\nshape of training data: {X_train.shape}')\n",
    "print('\\n')\n",
    "print(f'Labels for data: {y_train}\\n\\nshape of labels for training: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emojify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0de32f817056e671cdbf40ff462141a50ae4ac2f93dc11ac314f6f31243f04d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
